{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "131a323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from scipy.spatial.distance import jensenshannon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d96e402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cyclic_attractors(biological_attractor_file):\n",
    "    attrs = biological_attractor_file.iloc[:, 1:]\n",
    "    grouped_attrs = defaultdict(list)\n",
    "    pattern = re.compile(r\"^(.*)_s\\d+$\")\n",
    "    for col in attrs.columns:\n",
    "        match = pattern.match(col)\n",
    "        if match:\n",
    "            group_name = match.group(1)\n",
    "            grouped_attrs[group_name].append(col)\n",
    "            \n",
    "    biological_cycles = []\n",
    "    for group_name, cols in grouped_attrs.items():\n",
    "        cycle = []\n",
    "        for col in cols:\n",
    "            binary_str = ''.join(str(x) for x in attrs[col].astype(int).tolist())\n",
    "            reversed_str = binary_str[::-1]\n",
    "            decimal_val = int(reversed_str, 2)\n",
    "            cycle.append(str(decimal_val))\n",
    "        biological_cycles.append(cycle)\n",
    "    return biological_cycles\n",
    "\n",
    "\n",
    "\n",
    "def extract_fxd_pt_attractor(biological_attractor_file):\n",
    "    attrs = biological_attractor_file.iloc[:, 1:]\n",
    "    biological_fxd_pts = []\n",
    "    for col in attrs.columns:\n",
    "        binary_str = ''.join(str(x) for x in attrs[col].astype(int).tolist())\n",
    "        reversed_str = binary_str[::-1]\n",
    "        decimal_val = int(reversed_str, 2)\n",
    "        biological_fxd_pts.append(str(decimal_val))\n",
    "    return biological_fxd_pts\n",
    "\n",
    "\n",
    "def bio_and_thresh_maj_rule_attractors(model_no):\n",
    "    bio_and_thresh_maj_rule_att_dict = {category:{'fixed_points': None, 'cycles': None} for category in ['bio', 'ising', 'null']}\n",
    "    \n",
    "    bio_rule_attr_df = pd.read_csv(f'../input/att_details/att_details_all_files/bio_rule_attractors_model_{model_no}.tsv', sep = '\\t')\n",
    "    ising_maj_rule_attr_df = pd.read_csv(f'../input/att_details/att_details_all_files/majority_rule_attractors_model_{model_no}.tsv', sep = '\\t')\n",
    "    null_maj_rule_attr_df = pd.read_csv(f'../input/att_details/att_details_all_files/01_rule_attractors_model_{model_no}.tsv', sep = '\\t')\n",
    "    \n",
    "    bio_and_thresh_maj_rule_att_dict['bio']['fixed_points'] = eval(bio_rule_attr_df['fixed_points'][0])\n",
    "    bio_and_thresh_maj_rule_att_dict['bio']['cycles'] = eval(bio_rule_attr_df['cycles'][0])\n",
    "    \n",
    "    bio_and_thresh_maj_rule_att_dict['ising']['fixed_points'] = eval(ising_maj_rule_attr_df['fixed_points'][0])\n",
    "    bio_and_thresh_maj_rule_att_dict['ising']['cycles'] = eval(ising_maj_rule_attr_df['cycles'][0])\n",
    "    \n",
    "    bio_and_thresh_maj_rule_att_dict['null']['fixed_points'] = eval(null_maj_rule_attr_df['fixed_points'][0])\n",
    "    bio_and_thresh_maj_rule_att_dict['null']['cycles'] = eval(null_maj_rule_attr_df['cycles'][0])\n",
    " \n",
    "    return bio_and_thresh_maj_rule_att_dict\n",
    "\n",
    "\n",
    "\n",
    "def cyclic_att_intersection(cycle_list_1, cycle_list_2):\n",
    "    matched_elements = []\n",
    "    indices_in_cycle_list_1 = []\n",
    "    indices_in_cycle_list_2 = []\n",
    "    \n",
    "    for i, a in enumerate(cycle_list_1):\n",
    "        for j, b in enumerate(cycle_list_2):\n",
    "            if len(a) == len(b) and any(a == b[k:] + b[:k] for k in range(len(b))):\n",
    "                matched_elements.append(a)\n",
    "                indices_in_cycle_list_1.append(i)\n",
    "                indices_in_cycle_list_2.append(j)\n",
    "    \n",
    "    return matched_elements, indices_in_cycle_list_1, indices_in_cycle_list_2\n",
    "\n",
    "\n",
    "\n",
    "def fxd_att_intersection_info(fxd_pt_list_1, fxd_pt_list_2):\n",
    "    matched_elements = []\n",
    "    indices_in_fxd_pt_list_1 = []\n",
    "    indices_in_fxd_pt_list_2 = []\n",
    "\n",
    "    for i, a in enumerate(fxd_pt_list_1):\n",
    "        if a in fxd_pt_list_2:\n",
    "            j = fxd_pt_list_2.index(a)  # index of first occurrence in B\n",
    "            matched_elements.append(a)\n",
    "            indices_in_fxd_pt_list_1.append(i)\n",
    "            indices_in_fxd_pt_list_2.append(j)\n",
    "\n",
    "    return matched_elements, indices_in_fxd_pt_list_1, indices_in_fxd_pt_list_2\n",
    "\n",
    "\n",
    "def fxd_pts_basin_fraction (model, att_details_bio, att_details_ising, att_details_null):\n",
    "    \n",
    "    bio_attr_basin_in_bio_model, bio_attr_basin_in_ising_model, bio_attr_basin_in_null_model = [], [], []\n",
    "    \n",
    "#     att_details_bio = pd.read_csv('../../../Biodivine_analysis/attrprops_data_biomodel/output/bio_rule/all_bio_rule_attprops.tsv', sep = '\\t')\n",
    "#     att_details_ising = pd.read_csv('../../../Biodivine_analysis/attrprops_data_biomodel/output/majority_rule/all_majority_rule_attprops.tsv', sep = '\\t')\n",
    "#     att_details_null = pd.read_csv('../../../Biodivine_analysis/attrprops_data_biomodel/output/01_rule/all_01_rule_attprops.tsv', sep = '\\t')\n",
    "    \n",
    "    relev_bio = att_details_bio[att_details_bio['model_number'] == model]\n",
    "    relev_ising = att_details_ising[att_details_ising['model_number'] == model]\n",
    "    relev_null = att_details_null[att_details_null['model_number'] == model]\n",
    "    \n",
    "\n",
    "    fxd_pt_bio_meaning_attract_df = pd.read_csv(f'../input/biological_attractor_files/attractor_model_{model}.tsv', sep = '\\t')\n",
    "    p_fxd = extract_fxd_pt_attractor(fxd_pt_bio_meaning_attract_df)\n",
    "    all_att = bio_and_thresh_maj_rule_attractors(model)\n",
    "    \n",
    "    \n",
    "    p_m_intersection = fxd_att_intersection_info(p_fxd, all_att['bio']['fixed_points'])\n",
    "    p_n_ising_intersection = fxd_att_intersection_info(p_fxd, all_att['ising']['fixed_points'])\n",
    "    p_n_null_intersection = fxd_att_intersection_info(p_fxd, all_att['null']['fixed_points'])\n",
    "\n",
    "    for val in p_m_intersection[2]:\n",
    "        matched_values = relev_bio.loc[relev_bio['attractor_number'] == val+1, 'attractor_basin_size'].tolist()\n",
    "        bio_attr_basin_in_bio_model.extend(matched_values)\n",
    "    \n",
    "   \n",
    "    for i in range(len(p_fxd)):  \n",
    "        if i in p_n_ising_intersection[1]:\n",
    "            idx = p_n_ising_intersection[1].index(i) \n",
    "            val = p_n_ising_intersection[2][idx]+1\n",
    "            matched_values = relev_ising.loc[relev_ising['attractor_number'] == val, 'attractor_basin_size'].tolist()\n",
    "            bio_attr_basin_in_ising_model.extend(matched_values)\n",
    "        else:\n",
    "            bio_attr_basin_in_ising_model.append(0)\n",
    "            \n",
    "    for i in range(len(p_fxd)):  \n",
    "        if i in p_n_null_intersection[1]:\n",
    "            idx = p_n_null_intersection[1].index(i) \n",
    "            val = p_n_null_intersection[2][idx]+1\n",
    "            matched_values = relev_null.loc[relev_null['attractor_number'] == val, 'attractor_basin_size'].tolist()\n",
    "            bio_attr_basin_in_null_model.extend(matched_values)\n",
    "        else:\n",
    "            bio_attr_basin_in_null_model.append(0)\n",
    "    \n",
    "    \n",
    "    return bio_attr_basin_in_bio_model/relev_bio['attractor_basin_size'].sum(), bio_attr_basin_in_ising_model/relev_ising['attractor_basin_size'].sum(), bio_attr_basin_in_null_model/relev_null['attractor_basin_size'].sum()\n",
    "\n",
    "\n",
    "\n",
    "def cycle_basin_fraction (model, att_details_bio, att_details_ising, att_details_null):\n",
    "    bio_attr_basin_in_bio_model, bio_attr_basin_in_ising_model, bio_attr_basin_in_null_model = [], [], []\n",
    "    for types in ['bio', 'ising', 'null']:\n",
    "        globals()[f'relev_{types}'] = globals()[f'att_details_{types}'][globals()[f'att_details_{types}']['model_number'] == model]\n",
    "        globals()[f'relev_{types}_cycles'] = globals()[f'relev_{types}'][globals()[f'relev_{types}']['attractor_length'] != 1]\n",
    "        \n",
    "\n",
    "    cycle_bio_meaning_attract_df = pd.read_csv(f'../input/biological_attractor_files/cyclic_attractor_model_{model}.tsv', sep = '\\t')\n",
    "    p_cycle = extract_cyclic_attractors(cycle_bio_meaning_attract_df)\n",
    "    all_att = bio_and_thresh_maj_rule_attractors(model)\n",
    "    \n",
    "    \n",
    "    p_m_intersection = cyclic_att_intersection(p_cycle, all_att['bio']['cycles'])\n",
    "    p_n_ising_intersection = cyclic_att_intersection(p_cycle, all_att['ising']['cycles'])\n",
    "    p_n_null_intersection = cyclic_att_intersection(p_cycle, all_att['null']['cycles'])\n",
    "    \n",
    "    \n",
    "    for val in p_m_intersection[2]:\n",
    "        matched_values = relev_bio_cycles.loc[relev_bio_cycles['attractor_number'] == val+relev_bio_cycles['attractor_number'].iloc[0], 'attractor_basin_size'].tolist()\n",
    "        bio_attr_basin_in_bio_model.extend(matched_values)\n",
    "        \n",
    "    for i in range(len(p_cycle)):  \n",
    "        if i in p_n_ising_intersection[1]:\n",
    "            idx = p_n_ising_intersection[1].index(i) \n",
    "            val = p_n_ising_intersection[2][idx]+ relev_ising_cycles['attractor_number'].iloc[0]\n",
    "            matched_values = relev_ising_cycles.loc[relev_ising_cycles['attractor_number'] == val, 'attractor_basin_size'].tolist()\n",
    "            bio_attr_basin_in_ising_model.extend(matched_values)\n",
    "        else:\n",
    "            bio_attr_basin_in_ising_model.append(0)\n",
    "            \n",
    "    for i in range(len(p_cycle)):  \n",
    "        if i in p_n_null_intersection[1]:\n",
    "            idx = p_n_null_intersection[1].index(i) \n",
    "            val = p_n_null_intersection[2][idx]+ relev_null_cycles['attractor_number'].iloc[0]\n",
    "            matched_values = relev_null_cycles.loc[relev_null_cycles['attractor_number'] == val, 'attractor_basin_size'].tolist()\n",
    "            bio_attr_basin_in_null_model.extend(matched_values)\n",
    "        else:\n",
    "            bio_attr_basin_in_null_model.append(0)\n",
    "            \n",
    "    return bio_attr_basin_in_bio_model/relev_bio['attractor_basin_size'].sum(), bio_attr_basin_in_ising_model/relev_ising['attractor_basin_size'].sum(), bio_attr_basin_in_null_model/relev_null['attractor_basin_size'].sum()\n",
    "\n",
    "\n",
    "def compute_basin_score_having_both_cycle_and_fxd_pt(tuple1, tuple2):\n",
    "    bio = tuple1[0]+tuple2[0]\n",
    "    ising = tuple1[1]+tuple2[1]\n",
    "    null = tuple1[2]+tuple2[2]\n",
    "    P = len(bio)\n",
    "    score = lambda typ: sum((t / s if all(x >= y for x, y in zip(typ, bio)) else min(1, t / s)) for s, t in zip(bio, typ)) / P\n",
    "    return score(ising), score(null)\n",
    "\n",
    "\n",
    "def compute_basin_score_having_either_cycle_or_fxd_pt(tuple1):\n",
    "    bio = tuple1[0]\n",
    "    ising = tuple1[1]\n",
    "    null = tuple1[2]\n",
    "    P = len(bio)\n",
    "    score = lambda typ: sum((t / s if all(x >= y for x, y in zip(typ, bio)) else min(1, t / s)) for s, t in zip(bio, typ)) / P\n",
    "    return score(ising), score(null)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6d9df6",
   "metadata": {},
   "source": [
    "We want to see how well the threshold majority rules recover the biological attractors and the corresponing basin sizes.<br>\n",
    "(1) Recovery of biological attractors: Suppose $M$, $N$ be the set of attractors that the original model and the threshold model recovers respectively. $P$ is the set of attractors that are biologically meaningful.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87e3803",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nums = [7,8,10,22,23,31,40,61,63,67,69,74,85,86,88,95,99,100,109,110,133,200,208,212]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9736d21",
   "metadata": {},
   "source": [
    "# Attractor recovery score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb8467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_data_dict = {'model_no':[], 'tot_nodes':[], 'max_indeg':[], 'mean_indeg':[], 'original_mod_jaccard':[], 'ising_maj_jaccard': [], 'null_maj_jaccard':[]}\n",
    "for model in model_nums:\n",
    "    all_att = bio_and_thresh_maj_rule_attractors(model)\n",
    "    jaccard_data_dict['model_no'].append(model)\n",
    "    \n",
    "    func_types = pd.read_csv(f'../../../Biodivine_analysis/Network_generation/output/original_network_info/model_{model}/func_type_details_{model}.tsv', sep = '\\t')\n",
    "    jaccard_data_dict['tot_nodes'].append(len(func_types))\n",
    "    jaccard_data_dict['max_indeg'].append(int(func_types['No. of inputs'].max()))\n",
    "    jaccard_data_dict['mean_indeg'].append(round(func_types['No. of inputs'].mean(), 3))\n",
    "    \n",
    "    if model in [23,95]:\n",
    "        fxd_pt_bio_meaning_attract_df = pd.read_csv(f'../input/biological_attractor_files/attractor_model_{model}.tsv', sep = '\\t')\n",
    "        cycle_bio_meaning_attract_df = pd.read_csv(f'../input/biological_attractor_files/cyclic_attractor_model_{model}.tsv', sep = '\\t')\n",
    "        p_fxd = extract_fxd_pt_attractor(fxd_pt_bio_meaning_attract_df)\n",
    "        p_cycle = extract_cyclic_attractors(cycle_bio_meaning_attract_df)\n",
    "        p_m_jaccard = (len(p_fxd)+len(p_cycle))/(len(all_att['bio']['fixed_points'])+len(all_att['bio']['cycles']))\n",
    "        \n",
    "        p_n_ising_intersection = len(fxd_att_intersection_info(p_fxd, all_att['ising']['fixed_points'])[0]) + len(cyclic_att_intersection(p_cycle, all_att['ising']['cycles'])[0])\n",
    "        p_n_ising_union = len(all_att['ising']['fixed_points'])+len(all_att['ising']['cycles'])+len(p_fxd)+len(p_cycle)-p_n_ising_intersection\n",
    "        p_n_ising_jaccard = p_n_ising_intersection/p_n_ising_union\n",
    "        \n",
    "        p_n_null_intersection = len(fxd_att_intersection_info(p_fxd, all_att['null']['fixed_points'])[0]) + len(cyclic_att_intersection(p_cycle, all_att['null']['cycles'])[0])\n",
    "        p_n_null_union = len(all_att['null']['fixed_points'])+len(all_att['null']['cycles'])+len(p_fxd)+len(p_cycle)-p_n_null_intersection\n",
    "        p_n_null_jaccard = p_n_null_intersection/p_n_null_union\n",
    "        \n",
    "        \n",
    "    elif model in [31, 69, 109]:\n",
    "        cycle_bio_meaning_attract_df = pd.read_csv(f'../input/biological_attractor_files/cyclic_attractor_model_{model}.tsv', sep = '\\t')\n",
    "        p_cycle = extract_cyclic_attractors(cycle_bio_meaning_attract_df)\n",
    "        \n",
    "        p_m_jaccard = len(p_cycle)/(len(all_att['bio']['fixed_points'])+len(all_att['bio']['cycles']))\n",
    "        \n",
    "        p_n_ising_intersection = len(cyclic_att_intersection(p_cycle, all_att['ising']['cycles'])[0])\n",
    "        p_n_ising_union = len(all_att['ising']['fixed_points'])+len(all_att['ising']['cycles'])+ len(p_cycle)-p_n_ising_intersection\n",
    "        p_n_ising_jaccard = p_n_ising_intersection/p_n_ising_union\n",
    "        \n",
    "        p_n_null_intersection = len(cyclic_att_intersection(p_cycle, all_att['null']['cycles'])[0])\n",
    "        p_n_null_union = len(all_att['null']['fixed_points'])+len(all_att['null']['cycles'])+ len(p_cycle)-p_n_null_intersection\n",
    "        p_n_null_jaccard = p_n_null_intersection/p_n_null_union\n",
    "\n",
    "            \n",
    "    else:\n",
    "        fxd_pt_bio_meaning_attract_df = pd.read_csv(f'../input/biological_attractor_files/attractor_model_{model}.tsv', sep = '\\t')\n",
    "        p_fxd = extract_fxd_pt_attractor(fxd_pt_bio_meaning_attract_df)\n",
    "        \n",
    "        p_m_jaccard = len(p_fxd)/(len(all_att['bio']['fixed_points'])+len(all_att['bio']['cycles']))\n",
    "        \n",
    "        p_n_ising_intersection = len(fxd_att_intersection_info(p_fxd, all_att['ising']['fixed_points'])[0])\n",
    "        p_n_ising_union = len(all_att['ising']['fixed_points'])+len(all_att['ising']['cycles'])+len(p_fxd)-p_n_ising_intersection\n",
    "        p_n_ising_jaccard = p_n_ising_intersection/p_n_ising_union\n",
    "        \n",
    "        p_n_null_intersection = len(fxd_att_intersection_info(p_fxd, all_att['null']['fixed_points'])[0])\n",
    "        p_n_null_union = len(all_att['null']['fixed_points'])+len(all_att['null']['cycles'])+len(p_fxd)-p_n_null_intersection\n",
    "        p_n_null_jaccard = p_n_null_intersection/p_n_null_union\n",
    "        \n",
    "        \n",
    "    jaccard_data_dict['original_mod_jaccard'].append(p_m_jaccard)\n",
    "    jaccard_data_dict['ising_maj_jaccard'].append(p_n_ising_jaccard)\n",
    "    jaccard_data_dict['null_maj_jaccard'].append(p_n_null_jaccard)\n",
    "    \n",
    "df = pd.DataFrame(jaccard_data_dict)\n",
    "df['att_recovery_score_ising'] = df['ising_maj_jaccard']/df['original_mod_jaccard']\n",
    "df['att_recovery_score_null'] = df['null_maj_jaccard']/df['original_mod_jaccard']\n",
    "#df.to_csv('../output/attractor_recovery.tsv', sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec52e23",
   "metadata": {},
   "source": [
    "# Basin recovery score using Jensen Shannon distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60318dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_details_bio = pd.read_csv('../../../Biodivine_analysis/attrprops_data_biomodel/output/bio_rule/all_bio_rule_attprops.tsv', sep = '\\t')\n",
    "att_details_ising = pd.read_csv('../../../Biodivine_analysis/attrprops_data_biomodel/output/majority_rule/all_majority_rule_attprops.tsv', sep = '\\t')\n",
    "att_details_null = pd.read_csv('../../../Biodivine_analysis/attrprops_data_biomodel/output/01_rule/all_01_rule_attprops.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89b7ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fxd_pt_basin_sizes_for_JS_test(model, att_details_bio, att_details_ising, att_details_null):\n",
    "    gold_std_basin_sizes_fxd_pts, spurious_bio_basins_fxd_pts,  ising_model_basin_sizes_fxd_pts, null_model_basin_sizes_fxd_pts = [], [], [], []\n",
    "        \n",
    "    relev_bio = att_details_bio[att_details_bio['model_number'] == model]\n",
    "    relev_ising = att_details_ising[att_details_ising['model_number'] == model]\n",
    "    relev_null = att_details_null[att_details_null['model_number'] == model]\n",
    "      \n",
    "    biological_fxd_pt_path = f\"../input/biological_attractor_files/attractor_model_{model}.tsv\"\n",
    "    if os.path.exists(biological_fxd_pt_path):\n",
    "        fxd_pt_bio_meaning_attract_df = pd.read_csv(biological_fxd_pt_path, sep='\\t')\n",
    "        p_fxd = extract_fxd_pt_attractor(fxd_pt_bio_meaning_attract_df)\n",
    "    else:\n",
    "        p_fxd = []\n",
    "    \n",
    "    all_att = bio_and_thresh_maj_rule_attractors(model)\n",
    "    \n",
    "    # Computing the gold standard for the published model\n",
    "    p_m_intersection = fxd_att_intersection_info(p_fxd, all_att['bio']['fixed_points'])\n",
    "    gold_standard_indices_in_bio = p_m_intersection[2]\n",
    "    spurious_bio_att_indices_in_bio = [ele for ele in np.arange(len(all_att['bio']['fixed_points'])) if ele not in gold_standard_indices_in_bio]\n",
    "    \n",
    "    for val in gold_standard_indices_in_bio:\n",
    "        matched_values = relev_bio.loc[relev_bio['attractor_number'] == val+1, 'attractor_basin_size'].tolist()\n",
    "        gold_std_basin_sizes_fxd_pts.extend(matched_values)\n",
    "        \n",
    "    for val in spurious_bio_att_indices_in_bio:\n",
    "        matched_values = relev_bio.loc[relev_bio['attractor_number'] == val+1, 'attractor_basin_size'].tolist()\n",
    "        spurious_bio_basins_fxd_pts.extend(matched_values)\n",
    "    \n",
    "    gold_std_basin_sizes_fxd_pts_for_bio = gold_std_basin_sizes_fxd_pts + [0]*len(spurious_bio_basins_fxd_pts)\n",
    "    bio_model_basin_sizes_fxd_pts = gold_std_basin_sizes_fxd_pts + spurious_bio_basins_fxd_pts\n",
    "    \n",
    "    \n",
    "    # Computing the gold standard for the ising model\n",
    "    p_n_ising_intersection = fxd_att_intersection_info(p_fxd, all_att['ising']['fixed_points'])\n",
    "    gold_std_basin_sizes_fxd_pts_for_ising = ([gold_std_basin_sizes_fxd_pts[i] for i in p_n_ising_intersection[1]]\n",
    "                                            + [gold_std_basin_sizes_fxd_pts[i] for i in range(len(gold_std_basin_sizes_fxd_pts)) if i not in p_n_ising_intersection[1]]\n",
    "                                            + [0]*(len(all_att['ising']['fixed_points']) - len(p_n_ising_intersection[1]))\n",
    "    )\n",
    "   \n",
    "    for val in p_n_ising_intersection[2]:\n",
    "        matched_values = relev_ising.loc[relev_ising['attractor_number'] == val+1, 'attractor_basin_size'].tolist()\n",
    "        ising_model_basin_sizes_fxd_pts.extend(matched_values)\n",
    "    \n",
    "        \n",
    "    ising_model_basin_sizes_fxd_pts = ising_model_basin_sizes_fxd_pts + [0]*(len(gold_std_basin_sizes_fxd_pts) - len(p_n_ising_intersection[2]))\n",
    "    \n",
    "    ising_indices_of_the_extra_attr = [ele for ele in np.arange(len(all_att['ising']['fixed_points'])) if ele not in p_n_ising_intersection[2]]\n",
    "    \n",
    "    for val in ising_indices_of_the_extra_attr:\n",
    "        matched_values = relev_ising.loc[relev_ising['attractor_number'] == val+1, 'attractor_basin_size'].tolist()\n",
    "        ising_model_basin_sizes_fxd_pts.extend(matched_values)\n",
    "\n",
    "   \n",
    "    # Computing the gold standard for the bit_based model  \n",
    "    p_n_null_intersection = fxd_att_intersection_info(p_fxd, all_att['null']['fixed_points'])\n",
    "    gold_std_basin_sizes_fxd_pts_for_null = ([gold_std_basin_sizes_fxd_pts[i] for i in p_n_null_intersection[1]]\n",
    "                                            + [gold_std_basin_sizes_fxd_pts[i] for i in range(len(gold_std_basin_sizes_fxd_pts)) if i not in p_n_null_intersection[1]]\n",
    "                                            + [0]*(len(all_att['null']['fixed_points']) - len(p_n_null_intersection[1]))\n",
    "    )\n",
    "   \n",
    "    for val in p_n_null_intersection[2]:\n",
    "        matched_values = relev_null.loc[relev_null['attractor_number'] == val+1, 'attractor_basin_size'].tolist()\n",
    "        null_model_basin_sizes_fxd_pts.extend(matched_values)\n",
    "    \n",
    "        \n",
    "    null_model_basin_sizes_fxd_pts = null_model_basin_sizes_fxd_pts + [0]*(len(gold_std_basin_sizes_fxd_pts) - len(p_n_null_intersection[2]))\n",
    "    \n",
    "    null_indices_of_the_extra_attr = [ele for ele in np.arange(len(all_att['null']['fixed_points'])) if ele not in p_n_null_intersection[2]]\n",
    "    \n",
    "    for val in null_indices_of_the_extra_attr:\n",
    "        matched_values = relev_null.loc[relev_null['attractor_number'] == val+1, 'attractor_basin_size'].tolist()\n",
    "        null_model_basin_sizes_fxd_pts.extend(matched_values)\n",
    "    \n",
    "\n",
    "    return gold_std_basin_sizes_fxd_pts_for_bio, bio_model_basin_sizes_fxd_pts, gold_std_basin_sizes_fxd_pts_for_ising, ising_model_basin_sizes_fxd_pts, gold_std_basin_sizes_fxd_pts_for_null, null_model_basin_sizes_fxd_pts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb6ac2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4, 28], [4, 28], [4, 28], [16, 16], [4, 28, 0, 0, 0], [20, 4, 4, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = 7\n",
    "fxd_pt_basin_sizes_for_JS_test(model, att_details_bio, att_details_ising, att_details_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e7fe58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle_basin_sizes_for_JS_test(model, att_details_bio, att_details_ising, att_details_null):\n",
    "    gold_std_basin_sizes_cycles, spurious_bio_basins_cycles,  ising_model_basin_sizes_cycles, null_model_basin_sizes_cycles = [], [], [], []\n",
    "    \n",
    "    relev_bio = att_details_bio[att_details_bio['model_number'] == model]\n",
    "    relev_ising = att_details_ising[att_details_ising['model_number'] == model]\n",
    "    relev_null = att_details_null[att_details_null['model_number'] == model]\n",
    "    \n",
    "    relev_bio_cycles = relev_bio[relev_bio['attractor_length'] != 1]\n",
    "    relev_ising_cycles = relev_ising[relev_ising['attractor_length'] != 1]\n",
    "    relev_null_cycles = relev_null[relev_null['attractor_length'] != 1]\n",
    "          \n",
    "    biological_cycle_path = f\"../input/biological_attractor_files/cyclic_attractor_model_{model}.tsv\"\n",
    "    if os.path.exists(biological_cycle_path):\n",
    "        cycle_bio_meaning_attract_df = pd.read_csv(biological_cycle_path, sep='\\t')\n",
    "        p_cycle = extract_cyclic_attractors(cycle_bio_meaning_attract_df)\n",
    "    else:\n",
    "        p_cycle = []\n",
    "\n",
    "    all_att = bio_and_thresh_maj_rule_attractors(model)\n",
    "\n",
    "    # Computing the gold standard for the published model\n",
    "    p_m_intersection = cyclic_att_intersection(p_cycle, all_att['bio']['cycles'])\n",
    "    gold_standard_indices_in_bio = p_m_intersection[2]\n",
    "    spurious_bio_att_indices_in_bio = [ele for ele in np.arange(len(all_att['bio']['cycles'])) if ele not in gold_standard_indices_in_bio]\n",
    "\n",
    "    for val in gold_standard_indices_in_bio:\n",
    "        matched_values = relev_bio_cycles.loc[relev_bio_cycles['attractor_number'] == val+relev_bio_cycles['attractor_number'].iloc[0], 'attractor_basin_size'].tolist()\n",
    "        gold_std_basin_sizes_cycles.extend(matched_values)\n",
    "\n",
    "    for val in spurious_bio_att_indices_in_bio:\n",
    "        matched_values = relev_bio_cycles.loc[relev_bio_cycles['attractor_number'] == val+relev_bio_cycles['attractor_number'].iloc[0], 'attractor_basin_size'].tolist()\n",
    "        spurious_bio_basins_cycles.extend(matched_values)\n",
    "\n",
    "    gold_std_basin_sizes_cycles_for_bio = gold_std_basin_sizes_cycles + [0]*len(spurious_bio_basins_cycles)\n",
    "    bio_model_basin_sizes_cycles = gold_std_basin_sizes_cycles + spurious_bio_basins_cycles\n",
    "\n",
    "\n",
    "    # Computing the gold standard for the ising model\n",
    "    p_n_ising_intersection = cyclic_att_intersection(p_cycle, all_att['ising']['cycles'])\n",
    "    gold_std_basin_sizes_cycles_for_ising = ([gold_std_basin_sizes_cycles[i] for i in p_n_ising_intersection[1]]\n",
    "                                        + [gold_std_basin_sizes_cycles[i] for i in range(len(gold_std_basin_sizes_cycles)) if i not in p_n_ising_intersection[1]]\n",
    "                                        + [0]*(len(all_att['ising']['cycles']) - len(p_n_ising_intersection[1]))\n",
    "    )\n",
    "\n",
    "    for val in p_n_ising_intersection[2]:\n",
    "        matched_values = relev_ising_cycles.loc[relev_ising_cycles['attractor_number'] == val+relev_ising_cycles['attractor_number'].iloc[0], 'attractor_basin_size'].tolist()\n",
    "        ising_model_basin_sizes_cycles.extend(matched_values)\n",
    "\n",
    "    ising_model_basin_sizes_cycles = ising_model_basin_sizes_cycles + [0]*(len(gold_std_basin_sizes_cycles) - len(p_n_ising_intersection[2]))\n",
    "\n",
    "    ising_indices_of_the_extra_attr = [ele for ele in np.arange(len(all_att['ising']['cycles'])) if ele not in p_n_ising_intersection[2]]\n",
    "\n",
    "\n",
    "    for val in ising_indices_of_the_extra_attr:\n",
    "        matched_values = relev_ising_cycles.loc[relev_ising_cycles['attractor_number'] == val+relev_ising_cycles['attractor_number'].iloc[0], 'attractor_basin_size'].tolist()\n",
    "        ising_model_basin_sizes_cycles.extend(matched_values)\n",
    "\n",
    "\n",
    "    # Computing the gold standard for the bit_based model\n",
    "    p_n_null_intersection = cyclic_att_intersection(p_cycle, all_att['null']['cycles'])\n",
    "    gold_std_basin_sizes_cycles_for_null = ([gold_std_basin_sizes_cycles[i] for i in p_n_null_intersection[1]]\n",
    "                                            + [gold_std_basin_sizes_cycles[i] for i in range(len(gold_std_basin_sizes_cycles)) if i not in p_n_null_intersection[1]]\n",
    "                                            + [0]*(len(all_att['null']['cycles']) - len(p_n_null_intersection[1]))\n",
    "    )\n",
    "\n",
    "    for val in p_n_null_intersection[2]:\n",
    "        matched_values = relev_null_cycles.loc[relev_null_cycles['attractor_number'] == val+relev_null_cycles['attractor_number'].iloc[0], 'attractor_basin_size'].tolist()\n",
    "        null_model_basin_sizes_cycles.extend(matched_values)\n",
    "\n",
    "\n",
    "    null_model_basin_sizes_cycles = null_model_basin_sizes_cycles + [0]*(len(gold_std_basin_sizes_cycles) - len(p_n_null_intersection[2]))\n",
    "    null_indices_of_the_extra_attr = [ele for ele in np.arange(len(all_att['null']['cycles'])) if ele not in p_n_null_intersection[2]]\n",
    "\n",
    "    for val in null_indices_of_the_extra_attr:\n",
    "        matched_values = relev_null_cycles.loc[relev_null_cycles['attractor_number'] == val+relev_null_cycles['attractor_number'].iloc[0], 'attractor_basin_size'].tolist()\n",
    "        null_model_basin_sizes_cycles.extend(matched_values)\n",
    "\n",
    "\n",
    "    return gold_std_basin_sizes_cycles_for_bio, bio_model_basin_sizes_cycles, gold_std_basin_sizes_cycles_for_ising, ising_model_basin_sizes_cycles, gold_std_basin_sizes_cycles_for_null, null_model_basin_sizes_cycles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a70efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = 95\n",
    "# cycle_basin_sizes_for_JS_test(model, att_details_bio, att_details_ising, att_details_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86b7f461",
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_reco_score_dict = {'model_no':[], 'tot_nodes':[], 'max_indeg':[], 'mean_indeg':[], 'bio_gold_std_JS_dist': [], 'ising_gold_std_JS_dist': [], 'bit_gold_std_JS_dist':[]}\n",
    "\n",
    "model_nums = [7,8,10,22,23,31,40,61,63,67,69,74,85,86,88,95,99,100,109,110,133,200,208,212]\n",
    "for model in model_nums:\n",
    "    basin_reco_score_dict['model_no'].append(model)\n",
    "\n",
    "    func_types = pd.read_csv(f'../../../Biodivine_analysis/Network_generation/output/original_network_info/model_{model}/func_type_details_{model}.tsv', sep = '\\t')\n",
    "    basin_reco_score_dict['tot_nodes'].append(len(func_types))\n",
    "    basin_reco_score_dict['max_indeg'].append(int(func_types['No. of inputs'].max()))\n",
    "    basin_reco_score_dict['mean_indeg'].append(round(func_types['No. of inputs'].mean(), 3))\n",
    "\n",
    "    att_details_bio = pd.read_csv('../../../Biodivine_analysis/attrprops_data_biomodel/output/bio_rule/all_bio_rule_attprops.tsv', sep = '\\t')\n",
    "    att_details_ising = pd.read_csv('../../../Biodivine_analysis/attrprops_data_biomodel/output/majority_rule/all_majority_rule_attprops.tsv', sep = '\\t')\n",
    "    att_details_null = pd.read_csv('../../../Biodivine_analysis/attrprops_data_biomodel/output/01_rule/all_01_rule_attprops.tsv', sep = '\\t')\n",
    "\n",
    "    fxd_pt_basins = fxd_pt_basin_sizes_for_JS_test(model, att_details_bio, att_details_ising, att_details_null)\n",
    "    cycle_basins = cycle_basin_sizes_for_JS_test(model, att_details_bio, att_details_ising, att_details_null)\n",
    "\n",
    "    norm_gold_std_for_bio = np.array(fxd_pt_basins[0] + cycle_basins[0]) / sum(fxd_pt_basins[0] + cycle_basins[0])\n",
    "    norm_bio_basin = np.array(fxd_pt_basins[1] + cycle_basins[1]) / sum(fxd_pt_basins[1] + cycle_basins[1])\n",
    "\n",
    "    norm_gold_std_for_ising = np.array(fxd_pt_basins[2] + cycle_basins[2]) / sum(fxd_pt_basins[2] + cycle_basins[2])\n",
    "    norm_ising_basin = np.array(fxd_pt_basins[3] + cycle_basins[3]) / sum(fxd_pt_basins[3] + cycle_basins[3])\n",
    "\n",
    "    norm_gold_std_for_null = np.array(fxd_pt_basins[4] + cycle_basins[4]) / sum(fxd_pt_basins[4] + cycle_basins[4])\n",
    "    norm_null_basin = np.array(fxd_pt_basins[5] + cycle_basins[5]) / sum(fxd_pt_basins[5] + cycle_basins[5])\n",
    "\n",
    "    basin_reco_score_dict['bio_gold_std_JS_dist'].append(jensenshannon(norm_gold_std_for_bio, norm_bio_basin, base=2))\n",
    "    basin_reco_score_dict['ising_gold_std_JS_dist'].append(jensenshannon(norm_gold_std_for_ising, norm_ising_basin, base=2))\n",
    "    basin_reco_score_dict['bit_gold_std_JS_dist'].append(jensenshannon(norm_gold_std_for_null, norm_null_basin, base=2))\n",
    "  \n",
    "    \n",
    "df = pd.DataFrame(basin_reco_score_dict)\n",
    "df.to_csv('../output/basin_recovery_JS_distance.tsv', sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510c7e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff82b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea880ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208a9235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a4964c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1b9019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdfbe0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca5da7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670472a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3163284e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
